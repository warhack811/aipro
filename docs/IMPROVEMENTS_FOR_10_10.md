# ğŸ¯ Mami AI - 10/10 Ä°Ã§in Gerekli Ä°yileÅŸtirmeler

**Tarih:** 2025-12-12  
**Hedef:** TÃ¼m sistemleri 10/10 kaliteye Ã§Ä±karmak  
**Tahmini SÃ¼re:** 2-3 hafta

---

## ğŸ“Š Mevcut Durum vs Hedef

| Sistem | Mevcut | Hedef | Eksik |
|--------|--------|-------|-------|
| Prompt KatmanlarÄ± | 9/10 | 10/10 | Versioning, Analytics |
| HafÄ±za & RAG | 8/10 | 10/10 | Decay, Summarization |
| Sohbet GeÃ§miÅŸi | 8/10 | 10/10 | Sliding Window, Cache |
| GÃ¶rsel Ãœretim | 9/10 | 10/10 | Batch, History |
| Mod/Persona | 9/10 | 10/10 | Custom Persona |
| SansÃ¼r Sistemi | 7/10 | 10/10 | ML Detection, Audit |
| Router Sistemi | 9/10 | 10/10 | Cache, Analytics |
| Ä°nternet Arama | 8/10 | 10/10 | Cache, More Parsers |

---

## 1. PROMPT KATMANLARI â†’ 10/10

### Mevcut: 9/10 | Eksik: 1 puan

#### 1.1 Prompt Versioning Sistemi

**Dosya:** `app/ai/prompts/version_manager.py` (YENÄ°)

```python
"""
Prompt Version Manager
======================
Prompt deÄŸiÅŸikliklerini takip eder, A/B test desteÄŸi saÄŸlar.
"""

from dataclasses import dataclass
from typing import Dict, Optional
from datetime import datetime
import hashlib

@dataclass
class PromptVersion:
    version: str           # "v1.2.3"
    hash: str              # Ä°Ã§erik hash'i
    created_at: datetime
    author: str
    changelog: str
    is_active: bool = True
    ab_test_weight: float = 1.0  # A/B test iÃ§in aÄŸÄ±rlÄ±k

class PromptVersionManager:
    """Prompt versiyonlarÄ±nÄ± yÃ¶netir."""
    
    def __init__(self):
        self.versions: Dict[str, PromptVersion] = {}
        self.active_version: str = "v1.0.0"
    
    def register_version(self, version: str, prompt_content: str, changelog: str):
        """Yeni prompt versiyonu kaydeder."""
        content_hash = hashlib.sha256(prompt_content.encode()).hexdigest()[:12]
        self.versions[version] = PromptVersion(
            version=version,
            hash=content_hash,
            created_at=datetime.now(),
            author="system",
            changelog=changelog,
        )
    
    def get_prompt_for_user(self, user_id: int) -> str:
        """A/B test iÃ§in kullanÄ±cÄ±ya uygun prompt versiyonunu dÃ¶ndÃ¼rÃ¼r."""
        # User ID'ye gÃ¶re consistent hash ile versiyon seÃ§
        pass
    
    def rollback(self, version: str):
        """Ã–nceki versiyona geri dÃ¶n."""
        pass
    
    def get_stats(self) -> Dict:
        """Versiyon istatistikleri (hangi versiyon daha iyi performans)."""
        pass
```

#### 1.2 Prompt Analytics

**Dosya:** `app/services/prompt_analytics.py` (YENÄ°)

```python
"""
Prompt Analytics
================
Prompt performansÄ±nÄ± Ã¶lÃ§er.
"""

from dataclasses import dataclass
from typing import Dict, List

@dataclass
class PromptMetrics:
    version: str
    total_requests: int
    avg_response_time_ms: float
    avg_token_count: int
    user_satisfaction_rate: float  # like/dislike oranÄ±
    error_rate: float

class PromptAnalytics:
    """Prompt performans analizi."""
    
    def record_request(self, version: str, response_time: float, tokens: int):
        """Ä°stek kaydeder."""
        pass
    
    def record_feedback(self, version: str, is_positive: bool):
        """KullanÄ±cÄ± feedback'i kaydeder."""
        pass
    
    def get_best_performing_version(self) -> str:
        """En iyi performans gÃ¶steren versiyonu dÃ¶ndÃ¼rÃ¼r."""
        pass
    
    def generate_report(self) -> Dict:
        """Performans raporu Ã¼retir."""
        pass
```

**Entegrasyon:**
```python
# app/ai/prompts/compiler.py iÃ§inde
from app.ai.prompts.version_manager import prompt_version_manager
from app.services.prompt_analytics import prompt_analytics

def build_system_prompt(user=None, persona_name="standard", toggles=None):
    # Mevcut kod...
    
    # Analytics tracking
    prompt_analytics.record_request(
        version=prompt_version_manager.active_version,
        tokens=_estimate_tokens(final_prompt)
    )
    
    return final_prompt
```

---

## 2. HAFIZA & RAG SÄ°STEMÄ° â†’ 10/10

### Mevcut: 8/10 | Eksik: 2 puan

#### 2.1 Memory Decay Mechanism

**Dosya:** `app/memory/decay.py` (YENÄ°)

```python
"""
Memory Decay System
===================
KullanÄ±lmayan hafÄ±zalarÄ±n Ã¶nemini zamanla azaltÄ±r.
"""

from datetime import datetime, timedelta
from typing import List
import math

class MemoryDecay:
    """HafÄ±za decay yÃ¶neticisi."""
    
    # Decay parametreleri
    HALF_LIFE_DAYS = 30  # 30 gÃ¼nde yarÄ± Ã¶mÃ¼r
    MIN_IMPORTANCE = 0.1  # Minimum importance
    USAGE_BOOST = 0.2    # KullanÄ±mda artÄ±ÅŸ
    
    def calculate_decayed_importance(
        self, 
        original_importance: float,
        created_at: datetime,
        last_accessed: datetime
    ) -> float:
        """
        Exponential decay ile gÃ¼ncel importance hesaplar.
        
        Formula: I(t) = Iâ‚€ Ã— (0.5)^(t/TÂ½)
        """
        now = datetime.now()
        days_since_access = (now - last_accessed).days
        
        decay_factor = math.pow(0.5, days_since_access / self.HALF_LIFE_DAYS)
        decayed = original_importance * decay_factor
        
        return max(decayed, self.MIN_IMPORTANCE)
    
    def boost_on_access(self, current_importance: float) -> float:
        """HafÄ±za kullanÄ±ldÄ±ÄŸÄ±nda importance artÄ±r."""
        boosted = min(1.0, current_importance + self.USAGE_BOOST)
        return boosted
    
    def run_decay_job(self):
        """TÃ¼m hafÄ±zalar iÃ§in decay uygula (cron job)."""
        # memory_service Ã¼zerinden tÃ¼m hafÄ±zalarÄ± gÃ¼ncelle
        pass
```

#### 2.2 Hierarchical Memory Summarization

**Dosya:** `app/memory/summarizer.py` (YENÄ°)

```python
"""
Memory Summarizer
=================
50+ hafÄ±zasÄ± olan kullanÄ±cÄ±lar iÃ§in Ã¶zet Ã¼retir.
"""

from typing import List, Dict
from dataclasses import dataclass

@dataclass
class MemoryCluster:
    topic: str
    summary: str
    memory_ids: List[str]
    importance: float

class MemorySummarizer:
    """HafÄ±za Ã¶zetleyici."""
    
    CLUSTER_THRESHOLD = 50  # Bu sayÄ±dan fazla hafÄ±za varsa Ã¶zetle
    
    async def should_summarize(self, user_id: int) -> bool:
        """Ã–zet gerekli mi?"""
        count = await self._get_memory_count(user_id)
        return count >= self.CLUSTER_THRESHOLD
    
    async def cluster_memories(self, user_id: int) -> List[MemoryCluster]:
        """
        HafÄ±zalarÄ± konulara gÃ¶re kÃ¼mele.
        
        AdÄ±mlar:
        1. TÃ¼m hafÄ±zalarÄ± al
        2. Embedding'lere gÃ¶re k-means clustering
        3. Her kÃ¼me iÃ§in LLM ile Ã¶zet Ã¼ret
        """
        pass
    
    async def generate_user_profile(self, user_id: int) -> str:
        """
        KullanÄ±cÄ± profili Ã¶zeti Ã¼ret.
        
        Ã–rnek output:
        "Bu kullanÄ±cÄ± yazÄ±lÄ±m geliÅŸtiricisi, Python ve React kullanÄ±yor,
        Ä°stanbul'da yaÅŸÄ±yor, 2 Ã§ocuÄŸu var, futbol seviyor..."
        """
        pass
```

#### 2.3 RAG Chunking Ä°yileÅŸtirmesi

**Dosya:** `app/memory/rag.py` gÃ¼ncelleme

```python
# Mevcut chunk_text fonksiyonunu gÃ¼ncelle

def chunk_text_smart(
    text: str,
    chunk_size: int = 500,
    overlap: int = 100,  # 50'den 100'e artÄ±r
    respect_sentences: bool = True  # CÃ¼mle sÄ±nÄ±rlarÄ±na dikkat et
) -> List[str]:
    """
    AkÄ±llÄ± metin chunking.
    
    Ä°yileÅŸtirmeler:
    - CÃ¼mle ortasÄ±ndan bÃ¶lme
    - Daha fazla overlap
    - Paragraf Ã¶nceliÄŸi
    """
    if not respect_sentences:
        return _simple_chunk(text, chunk_size, overlap)
    
    # CÃ¼mlelere bÃ¶l
    sentences = _split_into_sentences(text)
    
    chunks = []
    current_chunk = []
    current_length = 0
    
    for sentence in sentences:
        if current_length + len(sentence) > chunk_size and current_chunk:
            # Chunk'Ä± kaydet
            chunks.append(" ".join(current_chunk))
            
            # Overlap iÃ§in son cÃ¼mleleri tut
            overlap_sentences = []
            overlap_length = 0
            for s in reversed(current_chunk):
                if overlap_length + len(s) <= overlap:
                    overlap_sentences.insert(0, s)
                    overlap_length += len(s)
                else:
                    break
            
            current_chunk = overlap_sentences
            current_length = overlap_length
        
        current_chunk.append(sentence)
        current_length += len(sentence)
    
    if current_chunk:
        chunks.append(" ".join(current_chunk))
    
    return chunks
```

---

## 3. SOHBET GEÃ‡MÄ°ÅÄ° â†’ 10/10

### Mevcut: 8/10 | Eksik: 2 puan

#### 3.1 Sliding Window + Summary

**Dosya:** `app/chat/processor.py` gÃ¼ncelleme

```python
def build_history_sliding_window(
    username: str,
    conversation_id: str,
    window_size: int = 10,
    include_summary: bool = True
) -> List[Dict[str, str]]:
    """
    Sliding window ile history oluÅŸtur.
    
    Format:
    [Ã–ZET] Ä°lk 20 mesajÄ±n Ã¶zeti
    [SON 10 MESAJ] Tam mesajlar
    """
    from app.memory.conversation import get_messages, get_summary
    
    messages = get_messages(conversation_id)
    
    if len(messages) <= window_size:
        return messages
    
    result = []
    
    # Ã–zet ekle
    if include_summary:
        summary = get_summary(conversation_id)
        if summary:
            result.append({
                "role": "system",
                "content": f"[Ã–NCEKÄ° SOHBET Ã–ZETÄ°]\n{summary}"
            })
    
    # Son N mesajÄ± tam ekle
    result.extend(messages[-window_size:])
    
    return result
```

#### 3.2 Message Importance Scoring

**Dosya:** `app/services/message_scorer.py` (YENÄ°)

```python
"""
Message Importance Scorer
=========================
Her mesaja Ã¶nem skoru atar, truncation'da kullanÄ±lÄ±r.
"""

from typing import Dict, List

class MessageScorer:
    """Mesaj Ã¶nem skorlayÄ±cÄ±."""
    
    # Ã–nem faktÃ¶rleri
    FACTORS = {
        "contains_name": 0.3,      # KullanÄ±cÄ± adÄ± geÃ§iyor
        "contains_memory": 0.4,    # HafÄ±zaya kaydedilmiÅŸ bilgi
        "is_question": 0.2,        # Soru iÃ§eriyor
        "has_code": 0.3,           # Kod bloÄŸu var
        "recent": 0.5,             # Son 5 mesaj
        "user_feedback": 0.5,      # Like almÄ±ÅŸ
    }
    
    def score_message(self, message: Dict, position: int, total: int) -> float:
        """Mesaja 0-1 arasÄ± Ã¶nem skoru atar."""
        score = 0.0
        
        content = message.get("content", "")
        metadata = message.get("metadata", {})
        
        # Ä°sim kontrolÃ¼
        if "benim adÄ±m" in content.lower() or "adÄ±m" in content.lower():
            score += self.FACTORS["contains_name"]
        
        # Son mesajlar daha Ã¶nemli
        if position >= total - 5:
            score += self.FACTORS["recent"]
        
        # Kod bloÄŸu varsa Ã¶nemli
        if "```" in content:
            score += self.FACTORS["has_code"]
        
        # Feedback varsa
        if metadata.get("liked"):
            score += self.FACTORS["user_feedback"]
        
        return min(1.0, score)
    
    def select_important_messages(
        self, 
        messages: List[Dict], 
        token_budget: int
    ) -> List[Dict]:
        """Token budget iÃ§inde en Ã¶nemli mesajlarÄ± seÃ§."""
        scored = []
        for i, msg in enumerate(messages):
            score = self.score_message(msg, i, len(messages))
            scored.append((score, i, msg))
        
        # Skora gÃ¶re sÄ±rala, budget iÃ§inde seÃ§
        scored.sort(reverse=True)
        
        selected = []
        total_tokens = 0
        
        for score, idx, msg in scored:
            msg_tokens = len(msg.get("content", "")) // 4
            if total_tokens + msg_tokens <= token_budget:
                selected.append((idx, msg))
                total_tokens += msg_tokens
        
        # Orijinal sÄ±raya gÃ¶re dÃ¶ndÃ¼r
        selected.sort(key=lambda x: x[0])
        return [msg for idx, msg in selected]
```

#### 3.3 Context Caching

**Dosya:** `app/services/context_cache.py` (YENÄ°)

```python
"""
Context Cache
=============
AynÄ± sohbet iÃ§in context'i cache'le.
"""

from typing import Dict, Optional
from datetime import datetime, timedelta
import hashlib

class ContextCache:
    """Context cache yÃ¶neticisi."""
    
    TTL_SECONDS = 60  # 1 dakika cache
    
    def __init__(self):
        self._cache: Dict[str, Dict] = {}
    
    def _make_key(self, conversation_id: str, message_count: int) -> str:
        """Cache key oluÅŸtur."""
        return f"{conversation_id}:{message_count}"
    
    def get(self, conversation_id: str, message_count: int) -> Optional[str]:
        """Cache'den context al."""
        key = self._make_key(conversation_id, message_count)
        
        if key not in self._cache:
            return None
        
        entry = self._cache[key]
        if datetime.now() > entry["expires_at"]:
            del self._cache[key]
            return None
        
        return entry["context"]
    
    def set(self, conversation_id: str, message_count: int, context: str):
        """Context'i cache'le."""
        key = self._make_key(conversation_id, message_count)
        self._cache[key] = {
            "context": context,
            "expires_at": datetime.now() + timedelta(seconds=self.TTL_SECONDS)
        }
    
    def invalidate(self, conversation_id: str):
        """Sohbet iÃ§in tÃ¼m cache'i temizle."""
        prefix = f"{conversation_id}:"
        keys_to_delete = [k for k in self._cache if k.startswith(prefix)]
        for key in keys_to_delete:
            del self._cache[key]

# Singleton
context_cache = ContextCache()
```

---

## 4. GÃ–RSEL ÃœRETÄ°M â†’ 10/10

### Mevcut: 9/10 | Eksik: 1 puan

#### 4.1 Batch Generation

**Dosya:** `app/image/batch_generator.py` (YENÄ°)

```python
"""
Batch Image Generator
=====================
Tek prompt ile birden fazla varyasyon Ã¼retir.
"""

from typing import List, Dict, Optional
from dataclasses import dataclass
import asyncio

@dataclass
class BatchJob:
    prompt: str
    variations: int
    seed_start: int
    job_ids: List[str]

class BatchGenerator:
    """Toplu gÃ¶rsel Ã¼retici."""
    
    MAX_VARIATIONS = 4
    
    async def generate_batch(
        self,
        prompt: str,
        user,
        variations: int = 4,
        variation_strength: float = 0.3
    ) -> List[str]:
        """
        AynÄ± prompt ile birden fazla varyasyon Ã¼ret.
        
        Args:
            prompt: Ana prompt
            variations: Ãœretilecek gÃ¶rsel sayÄ±sÄ±
            variation_strength: Varyasyon gÃ¼cÃ¼ (0-1)
        
        Returns:
            List[str]: Ãœretilen gÃ¶rsel URL'leri
        """
        from app.image.routing import decide_image_job
        from app.image.job_queue import image_job_queue
        
        variations = min(variations, self.MAX_VARIATIONS)
        
        # Her varyasyon iÃ§in farklÄ± seed
        base_seed = self._generate_base_seed()
        
        jobs = []
        for i in range(variations):
            # Prompt'a hafif varyasyon ekle
            varied_prompt = self._add_variation(prompt, i, variation_strength)
            
            spec = decide_image_job(varied_prompt, user)
            if not spec.blocked:
                job = await image_job_queue.enqueue(
                    prompt=varied_prompt,
                    user_id=user.id,
                    seed=base_seed + i,
                    batch_id=f"batch_{base_seed}"
                )
                jobs.append(job)
        
        # TÃ¼m job'larÄ±n tamamlanmasÄ±nÄ± bekle
        results = await asyncio.gather(*[
            self._wait_for_job(job) for job in jobs
        ])
        
        return [r for r in results if r is not None]
    
    def _add_variation(self, prompt: str, index: int, strength: float) -> str:
        """Prompt'a varyasyon ekle."""
        variations = [
            "",  # Orijinal
            ", slightly different angle",
            ", alternative composition",
            ", different lighting",
        ]
        return prompt + variations[index % len(variations)]
```

#### 4.2 Image History / Favorites

**Dosya:** `app/image/history.py` (YENÄ°)

```python
"""
Image History Manager
=====================
KullanÄ±cÄ±nÄ±n gÃ¶rsel geÃ§miÅŸini yÃ¶netir.
"""

from typing import List, Dict, Optional
from datetime import datetime

class ImageHistory:
    """GÃ¶rsel geÃ§miÅŸi yÃ¶neticisi."""
    
    MAX_HISTORY = 100  # KullanÄ±cÄ± baÅŸÄ±na max
    
    async def add_to_history(
        self,
        user_id: int,
        image_url: str,
        prompt: str,
        spec: Dict
    ):
        """GÃ¶rsel geÃ§miÅŸe ekle."""
        # DB'ye kaydet (UserImage modeli zaten var)
        pass
    
    async def get_history(
        self,
        user_id: int,
        limit: int = 50,
        offset: int = 0
    ) -> List[Dict]:
        """KullanÄ±cÄ±nÄ±n gÃ¶rsel geÃ§miÅŸini getir."""
        pass
    
    async def add_to_favorites(self, user_id: int, image_id: str):
        """GÃ¶rseli favorilere ekle."""
        pass
    
    async def get_favorites(self, user_id: int) -> List[Dict]:
        """Favori gÃ¶rselleri getir."""
        pass
    
    async def delete_from_history(self, user_id: int, image_id: str):
        """GeÃ§miÅŸten sil."""
        pass
    
    async def reuse_prompt(self, image_id: str) -> str:
        """GÃ¶rselin prompt'unu al (yeniden kullanÄ±m iÃ§in)."""
        pass
```

---

## 5. MOD/PERSONA SÄ°STEMÄ° â†’ 10/10

### Mevcut: 9/10 | Eksik: 1 puan

#### 5.1 Custom Persona Creator

**Dosya:** `app/services/custom_persona.py` (YENÄ°)

```python
"""
Custom Persona Manager
======================
KullanÄ±cÄ±larÄ±n kendi personalarÄ±nÄ± oluÅŸturmasÄ±na izin verir.
"""

from typing import Dict, Optional, List
from dataclasses import dataclass

@dataclass
class CustomPersona:
    id: str
    user_id: int
    name: str
    display_name: str
    system_prompt: str
    initial_message: Optional[str]
    avatar_url: Optional[str]
    is_public: bool = False  # DiÄŸer kullanÄ±cÄ±larla paylaÅŸ
    created_at: str

class CustomPersonaManager:
    """Ã–zel persona yÃ¶neticisi."""
    
    MAX_PERSONAS_PER_USER = 5
    MAX_PROMPT_LENGTH = 2000
    
    async def create_persona(
        self,
        user_id: int,
        name: str,
        display_name: str,
        system_prompt: str,
        initial_message: Optional[str] = None
    ) -> CustomPersona:
        """
        Yeni Ã¶zel persona oluÅŸtur.
        
        Validation:
        - Ä°sim unique olmalÄ±
        - Prompt length kontrolÃ¼
        - Max persona sayÄ±sÄ± kontrolÃ¼
        """
        # Limit kontrolÃ¼
        existing = await self.list_user_personas(user_id)
        if len(existing) >= self.MAX_PERSONAS_PER_USER:
            raise ValueError("Maksimum persona sayÄ±sÄ±na ulaÅŸtÄ±nÄ±z")
        
        # Prompt length
        if len(system_prompt) > self.MAX_PROMPT_LENGTH:
            raise ValueError("Prompt Ã§ok uzun")
        
        # OluÅŸtur ve kaydet
        persona = CustomPersona(
            id=self._generate_id(),
            user_id=user_id,
            name=name.lower().replace(" ", "_"),
            display_name=display_name,
            system_prompt=system_prompt,
            initial_message=initial_message,
            avatar_url=None,
            created_at=datetime.now().isoformat()
        )
        
        await self._save_persona(persona)
        return persona
    
    async def list_user_personas(self, user_id: int) -> List[CustomPersona]:
        """KullanÄ±cÄ±nÄ±n Ã¶zel personalarÄ±nÄ± listele."""
        pass
    
    async def delete_persona(self, user_id: int, persona_id: str):
        """Persona sil."""
        pass
    
    async def get_public_personas(self) -> List[CustomPersona]:
        """PaylaÅŸÄ±lan personalarÄ± listele."""
        pass
```

#### 5.2 Persona API Endpoints

**Dosya:** `app/api/user_routes.py` eklemeler

```python
# Mevcut persona endpoint'lerine ekle

@router.post("/personas/custom", response_model=CustomPersonaOut)
async def create_custom_persona(
    body: CustomPersonaIn,
    user: User = Depends(get_current_active_user)
):
    """Ã–zel persona oluÅŸtur."""
    from app.services.custom_persona import custom_persona_manager
    
    persona = await custom_persona_manager.create_persona(
        user_id=user.id,
        name=body.name,
        display_name=body.display_name,
        system_prompt=body.system_prompt,
        initial_message=body.initial_message,
    )
    
    return CustomPersonaOut.from_orm(persona)

@router.get("/personas/custom", response_model=List[CustomPersonaOut])
async def list_custom_personas(user: User = Depends(get_current_active_user)):
    """KullanÄ±cÄ±nÄ±n Ã¶zel personalarÄ±nÄ± listele."""
    pass

@router.delete("/personas/custom/{persona_id}")
async def delete_custom_persona(
    persona_id: str,
    user: User = Depends(get_current_active_user)
):
    """Ã–zel persona sil."""
    pass
```

---

## 6. SANSÃœR SÄ°STEMÄ° â†’ 10/10

### Mevcut: 7/10 | Eksik: 3 puan

#### 6.1 ML-Based Content Moderation

**Dosya:** `app/services/content_moderator.py` (YENÄ°)

```python
"""
ML-Based Content Moderator
==========================
Pattern matching'e ek olarak ML tabanlÄ± iÃ§erik analizi.
"""

from typing import Dict, List, Tuple
from dataclasses import dataclass
import aiohttp

@dataclass
class ModerationResult:
    is_flagged: bool
    categories: Dict[str, bool]
    scores: Dict[str, float]
    source: str  # "pattern", "openai", "local"

class ContentModerator:
    """Ä°Ã§erik moderatÃ¶rÃ¼."""
    
    def __init__(self):
        self.openai_available = self._check_openai_key()
    
    async def moderate(self, content: str) -> ModerationResult:
        """
        Ä°Ã§eriÄŸi analiz et.
        
        Cascade:
        1. HÄ±zlÄ± pattern matching (ucuz)
        2. OpenAI Moderation API (doÄŸru)
        3. Local fallback (offline)
        """
        # 1. Pattern matching (hÄ±zlÄ±, ilk filtre)
        pattern_result = self._pattern_check(content)
        if pattern_result.is_flagged:
            return pattern_result
        
        # 2. OpenAI Moderation API
        if self.openai_available:
            try:
                return await self._openai_moderate(content)
            except Exception:
                pass
        
        # 3. Pattern result as fallback
        return pattern_result
    
    def _pattern_check(self, content: str) -> ModerationResult:
        """Pattern-based hÄ±zlÄ± kontrol."""
        from app.image.routing import _detect_nsfw_in_prompt
        
        is_nsfw = _detect_nsfw_in_prompt(content)
        
        return ModerationResult(
            is_flagged=is_nsfw,
            categories={"nsfw": is_nsfw},
            scores={"nsfw": 1.0 if is_nsfw else 0.0},
            source="pattern"
        )
    
    async def _openai_moderate(self, content: str) -> ModerationResult:
        """OpenAI Moderation API Ã§aÄŸrÄ±sÄ±."""
        from app.config import get_settings
        
        settings = get_settings()
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://api.openai.com/v1/moderations",
                headers={"Authorization": f"Bearer {settings.OPENAI_API_KEY}"},
                json={"input": content}
            ) as resp:
                data = await resp.json()
        
        result = data["results"][0]
        
        return ModerationResult(
            is_flagged=result["flagged"],
            categories=result["categories"],
            scores=result["category_scores"],
            source="openai"
        )

# Singleton
content_moderator = ContentModerator()
```

#### 6.2 Audit Logging

**Dosya:** `app/services/moderation_audit.py` (YENÄ°)

```python
"""
Moderation Audit Logger
=======================
TÃ¼m moderation kararlarÄ±nÄ± loglar.
"""

from typing import Dict, Optional
from datetime import datetime
from dataclasses import dataclass

@dataclass
class AuditEntry:
    id: str
    timestamp: datetime
    user_id: int
    content_type: str  # "text", "image_prompt"
    content_hash: str  # Gizlilik iÃ§in hash
    decision: str      # "allowed", "blocked", "flagged"
    reason: str
    categories: Dict[str, bool]
    reviewed: bool = False
    reviewer_notes: Optional[str] = None

class ModerationAuditLogger:
    """Moderation audit logger."""
    
    async def log(
        self,
        user_id: int,
        content: str,
        content_type: str,
        decision: str,
        reason: str,
        categories: Dict[str, bool]
    ) -> str:
        """Audit kaydÄ± oluÅŸtur."""
        import hashlib
        
        entry = AuditEntry(
            id=self._generate_id(),
            timestamp=datetime.now(),
            user_id=user_id,
            content_type=content_type,
            content_hash=hashlib.sha256(content.encode()).hexdigest()[:16],
            decision=decision,
            reason=reason,
            categories=categories,
        )
        
        await self._save_entry(entry)
        return entry.id
    
    async def get_flagged_for_review(self, limit: int = 50) -> List[AuditEntry]:
        """Ä°ncelenmesi gereken kayÄ±tlarÄ± getir (admin panel iÃ§in)."""
        pass
    
    async def mark_reviewed(self, entry_id: str, notes: str):
        """KaydÄ± incelendi olarak iÅŸaretle."""
        pass
    
    async def get_stats(self) -> Dict:
        """Moderation istatistikleri."""
        return {
            "total_requests": 0,
            "blocked_count": 0,
            "flagged_count": 0,
            "false_positive_rate": 0.0,
        }

# Singleton
audit_logger = ModerationAuditLogger()
```

#### 6.3 User Report System

**Dosya:** `app/api/user_routes.py` eklemeler

```python
class ContentReportIn(BaseModel):
    content_id: str
    report_type: str  # "false_positive", "missed_nsfw", "other"
    description: Optional[str] = None

@router.post("/report/content")
async def report_content(
    body: ContentReportIn,
    user: User = Depends(get_current_active_user)
):
    """
    Ä°Ã§erik raporu gÃ¶nder.
    
    KullanÄ±cÄ± yanlÄ±ÅŸ engelleme veya kaÃ§an iÃ§erik bildirebilir.
    """
    from app.services.moderation_audit import audit_logger
    
    await audit_logger.add_user_report(
        user_id=user.id,
        content_id=body.content_id,
        report_type=body.report_type,
        description=body.description
    )
    
    return {"success": True, "message": "Raporunuz alÄ±ndÄ±"}
```

---

## 7. ROUTER SÄ°STEMÄ° â†’ 10/10

### Mevcut: 9/10 | Eksik: 1 puan

#### 7.1 Routing Cache

**Dosya:** `app/chat/routing_cache.py` (YENÄ°)

```python
"""
Routing Cache
=============
Benzer mesajlar iÃ§in routing kararÄ±nÄ± cache'le.
"""

from typing import Dict, Optional
from datetime import datetime, timedelta
import hashlib

class RoutingCache:
    """Routing kararÄ± cache."""
    
    TTL_SECONDS = 300  # 5 dakika
    
    def __init__(self):
        self._cache: Dict[str, Dict] = {}
    
    def _normalize_message(self, message: str) -> str:
        """MesajÄ± normalize et (cache key iÃ§in)."""
        # KÃ¼Ã§Ã¼k harf, boÅŸluklarÄ± temizle
        normalized = message.lower().strip()
        # SayÄ±larÄ± mask'le (hava durumu 15 derece vs 20 derece aynÄ± route)
        import re
        normalized = re.sub(r'\d+', 'NUM', normalized)
        return normalized
    
    def _make_key(self, message: str, persona: str) -> str:
        """Cache key oluÅŸtur."""
        normalized = self._normalize_message(message)
        key_input = f"{normalized}:{persona}"
        return hashlib.md5(key_input.encode()).hexdigest()
    
    def get(self, message: str, persona: str) -> Optional[str]:
        """Cache'den routing target al."""
        key = self._make_key(message, persona)
        
        if key not in self._cache:
            return None
        
        entry = self._cache[key]
        if datetime.now() > entry["expires_at"]:
            del self._cache[key]
            return None
        
        return entry["target"]
    
    def set(self, message: str, persona: str, target: str):
        """Routing kararÄ±nÄ± cache'le."""
        key = self._make_key(message, persona)
        self._cache[key] = {
            "target": target,
            "expires_at": datetime.now() + timedelta(seconds=self.TTL_SECONDS)
        }

routing_cache = RoutingCache()
```

#### 7.2 Routing Analytics (Prometheus)

**Dosya:** `app/services/routing_metrics.py` (YENÄ°)

```python
"""
Routing Metrics
===============
Prometheus metrikleri iÃ§in routing istatistikleri.
"""

from typing import Dict
from collections import defaultdict
from datetime import datetime

class RoutingMetrics:
    """Routing metrikleri."""
    
    def __init__(self):
        self.counters: Dict[str, int] = defaultdict(int)
        self.latencies: Dict[str, list] = defaultdict(list)
    
    def record_route(self, target: str, latency_ms: float):
        """Route kararÄ±nÄ± kaydet."""
        self.counters[f"route_{target}"] += 1
        self.latencies[target].append(latency_ms)
        
        # Son 1000 kaydÄ± tut
        if len(self.latencies[target]) > 1000:
            self.latencies[target] = self.latencies[target][-1000:]
    
    def get_prometheus_metrics(self) -> str:
        """Prometheus format metrikleri."""
        lines = []
        
        # Counters
        for key, value in self.counters.items():
            lines.append(f"mami_routing_{key}_total {value}")
        
        # Latency histograms
        for target, latencies in self.latencies.items():
            if latencies:
                avg = sum(latencies) / len(latencies)
                lines.append(f"mami_routing_{target}_latency_avg_ms {avg:.2f}")
        
        return "\n".join(lines)
    
    def get_dashboard_data(self) -> Dict:
        """Dashboard iÃ§in data."""
        total = sum(self.counters.values())
        
        distribution = {}
        for key, value in self.counters.items():
            target = key.replace("route_", "")
            distribution[target] = {
                "count": value,
                "percentage": (value / total * 100) if total > 0 else 0
            }
        
        return {
            "total_requests": total,
            "distribution": distribution,
        }

routing_metrics = RoutingMetrics()
```

---

## 8. Ä°NTERNET ARAMA â†’ 10/10

### Mevcut: 8/10 | Eksik: 2 puan

#### 8.1 Search Result Caching

**Dosya:** `app/search/cache.py` (YENÄ°)

```python
"""
Search Result Cache
===================
Arama sonuÃ§larÄ±nÄ± cache'le.
"""

from typing import Dict, List, Optional
from datetime import datetime, timedelta
import hashlib
import json

class SearchCache:
    """Arama sonuÃ§larÄ± cache."""
    
    # TTL by query type
    TTL_CONFIG = {
        "weather": 900,     # 15 dakika
        "exchange": 300,    # 5 dakika
        "sports": 1800,     # 30 dakika
        "general": 3600,    # 1 saat
    }
    
    def __init__(self):
        self._cache: Dict[str, Dict] = {}
    
    def _make_key(self, query: str) -> str:
        """Query'yi cache key'e dÃ¶nÃ¼ÅŸtÃ¼r."""
        normalized = query.lower().strip()
        return hashlib.md5(normalized.encode()).hexdigest()
    
    def _get_ttl(self, query_type: str) -> int:
        """Query tipine gÃ¶re TTL dÃ¶ndÃ¼r."""
        return self.TTL_CONFIG.get(query_type, self.TTL_CONFIG["general"])
    
    def get(self, query: str) -> Optional[List[Dict]]:
        """Cache'den sonuÃ§larÄ± al."""
        key = self._make_key(query)
        
        if key not in self._cache:
            return None
        
        entry = self._cache[key]
        if datetime.now() > entry["expires_at"]:
            del self._cache[key]
            return None
        
        return entry["results"]
    
    def set(self, query: str, results: List[Dict], query_type: str = "general"):
        """SonuÃ§larÄ± cache'le."""
        key = self._make_key(query)
        ttl = self._get_ttl(query_type)
        
        self._cache[key] = {
            "results": results,
            "query_type": query_type,
            "expires_at": datetime.now() + timedelta(seconds=ttl)
        }
    
    def clear_expired(self):
        """SÃ¼resi dolan cache'leri temizle."""
        now = datetime.now()
        keys_to_delete = [
            k for k, v in self._cache.items() 
            if now > v["expires_at"]
        ]
        for key in keys_to_delete:
            del self._cache[key]

search_cache = SearchCache()
```

#### 8.2 Daha Fazla Structured Parser

**Dosya:** `app/search/structured_parser.py` eklemeler

```python
# Mevcut parser'lara ek

def parse_movie_result(snippets: List, movie_name: str) -> Dict:
    """
    Film bilgisi parse et.
    
    Output:
    {
        "title": "Inception",
        "year": 2010,
        "director": "Christopher Nolan",
        "rating": 8.8,
        "genres": ["Sci-Fi", "Thriller"],
        "duration": "148 min"
    }
    """
    pass

def parse_wikipedia_result(snippets: List, topic: str) -> Dict:
    """
    Wikipedia Ã¶zeti parse et.
    
    Output:
    {
        "title": "Python (programming language)",
        "summary": "Python is a high-level...",
        "categories": ["Programming languages"],
        "url": "https://en.wikipedia.org/..."
    }
    """
    pass

def parse_product_price_result(snippets: List, product: str) -> Dict:
    """
    ÃœrÃ¼n fiyatÄ± parse et.
    
    Output:
    {
        "product": "iPhone 15 Pro",
        "price_range": {"min": 45000, "max": 55000},
        "currency": "TRY",
        "stores": [
            {"name": "Apple", "price": 54999},
            {"name": "Hepsiburada", "price": 52999}
        ]
    }
    """
    pass

def parse_recipe_result(snippets: List, dish: str) -> Dict:
    """
    Tarif bilgisi parse et.
    
    Output:
    {
        "name": "KarnÄ±yarÄ±k",
        "prep_time": "30 min",
        "cook_time": "45 min",
        "servings": 4,
        "ingredients": [...],
        "steps": [...]
    }
    """
    pass
```

#### 8.3 Search Rate Limiting

**Dosya:** `app/search/rate_limiter.py` (YENÄ°)

```python
"""
Search Rate Limiter
===================
KullanÄ±cÄ± bazlÄ± arama limiti.
"""

from typing import Dict
from datetime import datetime, timedelta

class SearchRateLimiter:
    """Arama rate limiter."""
    
    DAILY_LIMIT = 100  # GÃ¼nlÃ¼k max arama
    MINUTE_LIMIT = 10  # Dakikada max arama
    
    def __init__(self):
        self._daily_counts: Dict[int, Dict] = {}
        self._minute_counts: Dict[int, Dict] = {}
    
    def can_search(self, user_id: int) -> tuple[bool, str]:
        """KullanÄ±cÄ± arama yapabilir mi?"""
        now = datetime.now()
        today = now.date()
        current_minute = now.replace(second=0, microsecond=0)
        
        # GÃ¼nlÃ¼k limit kontrolÃ¼
        if user_id in self._daily_counts:
            entry = self._daily_counts[user_id]
            if entry["date"] == today and entry["count"] >= self.DAILY_LIMIT:
                return False, "GÃ¼nlÃ¼k arama limitinize ulaÅŸtÄ±nÄ±z"
        
        # Dakika limit kontrolÃ¼
        if user_id in self._minute_counts:
            entry = self._minute_counts[user_id]
            if entry["minute"] == current_minute and entry["count"] >= self.MINUTE_LIMIT:
                return False, "Ã‡ok fazla arama yapÄ±yorsunuz, lÃ¼tfen bekleyin"
        
        return True, ""
    
    def record_search(self, user_id: int):
        """Arama kaydÄ±."""
        now = datetime.now()
        today = now.date()
        current_minute = now.replace(second=0, microsecond=0)
        
        # GÃ¼nlÃ¼k sayaÃ§
        if user_id not in self._daily_counts or self._daily_counts[user_id]["date"] != today:
            self._daily_counts[user_id] = {"date": today, "count": 0}
        self._daily_counts[user_id]["count"] += 1
        
        # Dakika sayaÃ§
        if user_id not in self._minute_counts or self._minute_counts[user_id]["minute"] != current_minute:
            self._minute_counts[user_id] = {"minute": current_minute, "count": 0}
        self._minute_counts[user_id]["count"] += 1

search_rate_limiter = SearchRateLimiter()
```

---

## ğŸ“Š Ã–ZET: 10/10 Ä°Ã‡Ä°N TOPLAM Ä°Å

### Yeni Dosyalar (17 adet)

| Dosya | SatÄ±r | Ã–ncelik |
|-------|-------|---------|
| prompts/version_manager.py | ~100 | Orta |
| services/prompt_analytics.py | ~80 | Orta |
| memory/decay.py | ~60 | YÃ¼ksek |
| memory/summarizer.py | ~80 | Orta |
| services/message_scorer.py | ~100 | Orta |
| services/context_cache.py | ~60 | Orta |
| image/batch_generator.py | ~100 | DÃ¼ÅŸÃ¼k |
| image/history.py | ~80 | DÃ¼ÅŸÃ¼k |
| services/custom_persona.py | ~120 | Orta |
| services/content_moderator.py | ~100 | **YÃ¼ksek** |
| services/moderation_audit.py | ~80 | **YÃ¼ksek** |
| chat/routing_cache.py | ~60 | Orta |
| services/routing_metrics.py | ~80 | Orta |
| search/cache.py | ~80 | **YÃ¼ksek** |
| search/rate_limiter.py | ~60 | Orta |
| + structured_parser.py eklemeleri | ~200 | DÃ¼ÅŸÃ¼k |

**Toplam: ~1500 satÄ±r yeni kod**

### GÃ¼ncellenecek Dosyalar

| Dosya | DeÄŸiÅŸiklik |
|-------|------------|
| chat/processor.py | sliding_window, message_scoring |
| memory/rag.py | smart chunking |
| api/user_routes.py | custom persona, report endpoints |

---

## â±ï¸ TAHMÄ°NÄ° SÃœRE

| Ã–ncelik | Ä°ÅŸler | SÃ¼re |
|---------|-------|------|
| YÃ¼ksek | Moderation, Search Cache, Memory Decay | 3-4 gÃ¼n |
| Orta | Version Manager, Context Cache, Routing Cache | 3-4 gÃ¼n |
| DÃ¼ÅŸÃ¼k | Batch Gen, Custom Persona, Parsers | 2-3 gÃ¼n |

**TOPLAM: 8-11 iÅŸ gÃ¼nÃ¼ (~2 hafta)**

---

## ğŸ¯ Ã–NCELÄ°K SIRASI

1. **content_moderator.py + moderation_audit.py** (SansÃ¼r: 7â†’10)
2. **search/cache.py** (Arama: 8â†’10)
3. **memory/decay.py** (HafÄ±za: 8â†’10)
4. **chat/routing_cache.py** (Router: 9â†’10)
5. **services/context_cache.py** (Sohbet: 8â†’10)
6. **prompts/version_manager.py** (Prompt: 9â†’10)
7. DiÄŸerleri...

---

*Bu dokÃ¼man 10/10 hedefi iÃ§in gereken tÃ¼m iyileÅŸtirmeleri iÃ§erir.*  
*Tahmini tamamlanma: 2 hafta*  
*Son gÃ¼ncelleme: 2025-12-12*
